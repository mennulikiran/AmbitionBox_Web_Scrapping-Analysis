{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68170fb-9c0c-4471-a37f-fd05efdd2b2f",
   "metadata": {},
   "source": [
    "## Step - 1: Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1a2f9-1b7e-4888-ae5b-a91447762845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025ce15-a315-42e6-8f43-58a1240506c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    # 'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests':\n",
    "    '1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "}\n",
    "\n",
    "# Use a session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49ffe9-3dfc-41be-9752-3f8fa3ab77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "com_list = []\n",
    "ratings = []\n",
    "type_of_company = []\n",
    "reviews = []\n",
    "\n",
    "for i in range(1, 31):  # Pages 1-30\n",
    "    url = f\"https://www.ambitionbox.com/list-of-companies?campaign=desktop_nav&page={i}\"\n",
    "    \n",
    "    response = requests.get(url, headers=request_header)\n",
    "    \n",
    "    # Check if the request succeeded\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page {i}\")\n",
    "        continue\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    # Extract company names\n",
    "    for company_tag in soup.find_all(\"h2\", class_=\"companyCardWrapper__companyName\"):\n",
    "        com_list.append(company_tag.text.strip())  # Use strip() to clean whitespace\n",
    "    \n",
    "    time.sleep(2)  # Avoid overwhelming the server\n",
    "\n",
    "    # Extract ratings \n",
    "    for rate in soup.find_all(\"div\", class_=\"companyCardWrapper__companyRatingWrapper\"):\n",
    "        ratings.append(rate.text.strip())  # Use strip() to clean whitespace\n",
    "    \n",
    "    time.sleep(2)  # Avoid overwhelming the serve\n",
    "\n",
    "    # extract company_type\n",
    "    for type in soup.find_all(\"span\", class_=\"companyCardWrapper__interLinking\"):\n",
    "        type_of_company.append(type.text.strip())\n",
    "        \n",
    "    time.sleep(2)\n",
    "\n",
    "    # Extract Reviews\n",
    "    for review in soup.find_all(\"span\", class_=\"companyCardWrapper__ActionCount\"):\n",
    "        reviews.append(review.text.strip())\n",
    "        \n",
    "    time.sleep(2)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5e594-436c-4f9f-b149-deeb351cb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_types = []\n",
    "locations = []\n",
    "\n",
    "for item in type_of_company:\n",
    "    parts = item.split('|', 1)  # Split at first occurrence of '|'\n",
    "    \n",
    "    if len(parts) == 2:  \n",
    "        company_types.append(parts[0].strip())\n",
    "        locations.append(parts[1].strip())\n",
    "    else:  \n",
    "        company_types.append(\"Unknown\")  # Handle missing company type\n",
    "        locations.append(parts[0].strip())  # Treat full entry as location\n",
    "\n",
    "print(\"Company Types:\", company_types)\n",
    "print(\"Locations:\", locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caada172-051b-4b6c-8dce-39e88e2ecdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_1 = reviews[0::6]\n",
    "salaries = reviews[1::6]\n",
    "interviews = reviews[2::6]\n",
    "jobs = reviews[3::6]\n",
    "benefits = reviews[4::6]\n",
    "photos = reviews[5::6]\n",
    "#salaries, interviews, jobs, benefits, photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351476f-65c7-4447-8867-1e58fa404e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=[]\n",
    "for i in ratings:\n",
    "    r.append(i[:3])\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca9484-2014-4296-bb92-1c07f53836a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(com_list))\n",
    "print(len(ratings))\n",
    "print(len(type_of_company))\n",
    "print(len(reviews_1))\n",
    "print(len(salaries))\n",
    "print(len(interviews))\n",
    "print(len(jobs))\n",
    "print(len(benefits))\n",
    "print(len(photos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e54c5-6ae2-47d0-98a9-5efed7f4f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Company_Name':com_list,\n",
    "                  'Rating':r,\n",
    "                  'Industry_Type':company_types,\n",
    "                   'Headquater_other_Locations' :locations,\n",
    "                  'Total Reviews':reviews_1,\n",
    "                  'AvgSalaries':salaries,\n",
    "                  'Total_Interviews':interviews,\n",
    "                  'Total_Jobs':jobs,\n",
    "                  'Total_Benifits':benefits,\n",
    "                  'Total_Photos':photos})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c95f62-335c-4d94-b738-caa1753b788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Raw_Ambition_Box.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bb363-abcb-4254-89c0-e8427e12e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in com_list:\n",
    "    res = i.lower()\n",
    "    res_1 = res.replace(\" \", \"-\")\n",
    "    lst.append(res_1)\n",
    "for i in lst:\n",
    "    url = f\"https://www.ambitionbox.com/overview/{i}-overview\"\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0433e-f86d-4429-9068-0b301f6f886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ben=[]\n",
    "\n",
    "for i in lst:  # Pages 1-10\n",
    "    url = f\"https://www.ambitionbox.com/overview/{i}-overview\"\n",
    "    \n",
    "    response = requests.get(url, headers=request_header)\n",
    "    \n",
    "    # Check if the request succeeded\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page {i}\")\n",
    "        continue\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    # Extract company names\n",
    "    for company_tag in soup.find_all(\"div\", class_=\"css-175oi2r grid grid-cols-2 md:grid-cols-4 gap-3\"):\n",
    "        ben.append(company_tag.text.strip())  # Use strip() to clean whitespace\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b363ca-0fdd-4eea-89cf-7bc8926cd1eb",
   "metadata": {},
   "source": [
    "## Step - 2 : Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7614d7-a154-417a-a5b5-5b87dd2d29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61170bce-3ac5-45a7-bf4d-b8f05e6ec929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Raw_Ambition_Box.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae33dd-932a-4e08-b258-091a6c6c3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3) # top 3 data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474634cf-f6cb-4970-9e2e-72ded98fd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479628d7-f28c-4d49-bedc-6356c3836ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a79e86-9af3-4e17-9be2-855dc389f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41dc5e4-3e08-4d8e-8e65-31c51cd6e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ratings'] = df['Ratings'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78f345-acfe-4e3f-85c2-609c0767d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Reviews']=df['Total Reviews'].str.replace('k', '', regex=True).astype(float) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd028d-e36d-474c-bfcc-79b0b8a2aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Benifits']=df['Total_Benifits'].apply(lambda x: float(x.replace('k', '')) * 1000 if 'k' in x else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512377d-41d6-402b-bdf1-864a0bb3716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Interviews']=df['Total_Interviews'].apply(lambda x: float(x.replace('k', '')) * 1000 if 'k' in x else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a7bf3-65be-422b-9bb2-4f40d9a89e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert values\n",
    "def convert_values(x):\n",
    "    if 'k' in x:\n",
    "        return float(x.replace('k', '')) * 1000\n",
    "    elif x == '--':  # Handling missing values\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x)  # Keep numeric values as they are\n",
    "\n",
    "# Apply conversion\n",
    "df['Total_Jobs'] = df['Total_Jobs'].apply(convert_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad9f39-4cb7-49ba-8e65-5652b60958e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Total_Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49aedb-ab2b-40a9-a8da-84672aa051cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvgSalaries'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea56e7-22f5-431b-859d-5049b10c91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_values(x):\n",
    "    if 'k' in x:\n",
    "        return float(x.replace('k', '')) * 1000\n",
    "    elif 'L' in x:\n",
    "        return float(x.replace('L', '')) * 100000\n",
    "    else:\n",
    "        return float(x)  # Keep numeric values as they are\n",
    "\n",
    "# Apply conversion to column\n",
    "df['AvgSalaries'] = df['AvgSalaries'].apply(convert_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81097499-678d-4373-a3af-3635d012c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0aeaff-2901-4fae-a512-6cc49fefd195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Total Reviews', 'Total_Photos'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79d049-a95d-4f0a-a463-04322760a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/mnt/data/updated_Cleaned_Ambition_Box.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Selecting relevant features for imputation\n",
    "features = ['Total_Interviews', 'AvgSalaries', 'Total_Benifits']\n",
    "\n",
    "# Fill missing values in Total_Jobs using median based on Industry_Type\n",
    "df['Total_Jobs'] = df.groupby('Industry_Type')['Total_Jobs'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# If there are still missing values, fill with overall median\n",
    "df['Total_Jobs'].fillna(df['Total_Jobs'].median(), inplace=True)\n",
    "\n",
    "# Convert Total_Jobs to integer\n",
    "df['Total_Jobs'] = df['Total_Jobs'].astype(int)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"/mnt/data/filled_Cleaned_Ambition_Box.csv\", index=False)\n",
    "\n",
    "print(\"Missing values in Total_Jobs filled successfully using data analysis, and datatype converted to int!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb3182-b81b-4a33-a697-171b7d1eb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Cleaned_Ambition_Box.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dda04f-0726-4a79-b507-f86f6a6e1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
